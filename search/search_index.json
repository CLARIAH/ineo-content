{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Ineo Content At this stage this repository is a proposal! Introduction This repository stores the rich content for the Ineo Resource finder. We denote the various curated texts pertaining to resources as 'rich content'. A select team of CLARIAH's communication department is working on these texts. This repository enables easy collaboration, also with developers and data providers, and provides a sustainable storage solution. Rich content can be contrasted to the automatically harvested metadata that results from the CLARIAH Tool Discovery track or the FAIR Datasets track and is not supposed to overlap. For automatically harvested metadata, the primary authorship lies with the tool/data producer. For rich user content, it lies with the people of the communication department (WP1). The rich content in this repository is stored in Markdown format , a simple plain text format for text markup. We follow a specific structure to the data can be easily ingested into Ineo, as well as any other systems who want to make use of it. The content can be previewed directly on https://clariah.github.io/ineo-content . We used a simple static site generator ( MkDocs ) to achieve this. That site, however, is not intended for end-users to be used directly. On the preview site we also provide access to a simple headless CMS to facilitate working with the Markdown files in the git repository, without requiring real technical knowledge of either. Directory Structure Directories: src/ - Contains Markdown texts tools/ - Contains Markdown texts describing tools. data/ - Contains Markdown texts describing data workflows/ - Contains Markdown texts describing workflows standards/ - Contains Markdown texts describing standards media/ - Stores images or other associated media files, Right now all media files are in this single folder, without subfolders, this limitation is only due to the admin CMS. Images or downloadable documents/spreadsheets/presentations that are referenced from one of the markdown files may be included in this subdirectory as well. You can reference images from the markdown files, just use /media/ as URL prefix when doing so. You can also reference media elsewhere on the web, always sure to use https:// in that case. This should probably be kept to a minimum as there is no guarantee such media will persist in that location over time. Videos are not suitable for direct inclusion in the git repository as they are too big, they need to be hosted elsewhere. Ensure the media files you upload here are suitable for use on the web, pay attention to file-size, format and resolution. Within these directories, each resource is described by a single Markdown file, with optional YAML frontmatter . The title of the markdown file (a level-one heading, e.g. # ) corresponds with the title of the resource as shown in the frontend. The extension is always .md . The paragraph(s) immediately succeeding the level-one heading are taken to be the description, for tools (unless it concerns a tool suite), this generally be omitted as the description should be automatically drawn from the metadata. It is recommended to keep filename to a simple subset of lowercase ASCII characters, without spaces or any punctuation aside from dashes. The markdown file contains sections marked with level two headings ( ## ), each should correspond to agreed-upon tabs shown in the Ineo frontend, we currently distinguish the following: Overview Learn Mentions The content editors and frontend developers can introduce new ones when needed. Any subsections (level-three headings and beyond) can be used freely. YAML frontmatter The markdown files can be enriched with YAML frontmatter to convey some extra information. This is NOT intended for extensive tool/data metadata, as those come directly from different data provisioning pipelines and are not kept in this repository. The only metadata we always duplicate is the title of the resource, which typically also determines the filename (in a 'slug' form in lowercase only and with spaces replaced by hyphens). --- title: The title of the resource --- For tools , we use either the identifier or group field to link to https://tools.clariah.nl . The identifier links to an exact resource, such as frog for https://tools.clariah.nl/frog , i.e. it is identical to what appears in the URL. The other one, group , links to a group or tool suite because the level of granularity offered on https://tools.clariah.nl may be too fine-grained compared to what is desirable for Ineo or other portals. It should be exact name of the group as it appears on the tool discovery overview. The name s of the groups an be easily spotted by looking at the table of contents there; the groups are the ones with sub-items. --- identifier: tool title: Tool --- If both identifier and group are set, the identifier is used to associate metadata of one specific tool in the group/suite with the group as a whole. This allows you to still describe a whole tool suite in Ineo, but picks one of the tools in the suite as being its representative and have its metadata prominently features. The following Ineo-specific metadata can be added: (TODO: add specification of part of Ineo's YAML syntax that are reusable. This is something for the Ineo developers to specify.) Ineo currently allows for a carousel widget showing several images in sequence (see for example https://www.ineo.tools/resources/media-suite ). The data definition for such a widget would go in the YAML frontmatter, I would propose something like: --- carousel: - /media/mediasuite-cover1.png - https://vimeo.com/503507411?embedded=true&source=vimeo_logo&owner=115309374 - /media/mediasuite-cover2.png - /media/mediasuite-cover3.png - /media/mediasuite-cover4.png --- Note these are specifically for Ineo and won't be previewed in the editor. Whether you images interspersed in the flowing text (easier) or the carousel is up to the maintainer team to decide. Note that for data, no way of linking to underlying data registry via identifiers has been defined yet (take this up with Menzo). Template The following template serves as an example for tools: --- identifier: tool-identifier-from-tools-clariah-nl title: Name of the Tool carousel: - /media/tool-screenshot.png --- # Name of the Tool (a short description can go here) ## Overview (all text you want on the overview tab goes here) ## Learn (all text you want on the learn tab goes here) ## Mentions (all text you want on the mentions tab goes here) Editing Content Management System (CMS) A headless CMS ( DecapCMS previously known as NetlifyCMS) is available to make it easier for content editors to do their editing. Within the CMS, both the Markdown content and the YAML frontmatter can be edited in a WYSIWYG fashion without knowledge of either Markdown or YAML. A GitHub account is required to edit. The CMS can be accessed here The CMS is a nice convenience but it also enforced some limitations, it has put the following constraints on this specification: All media files are stored in a single directory /media/ and does not allow further divisions in subdirectories. Online IDE An alternative to using the CMS is to use GitHub's online Visual Studio Code IDE. Each page on https://clariah.github.io/ineo-content has an edit this page link that automatically takes you to the web-based IDE. This offers a bit more freedom than the CMS. Local editing Being a simple git repository with MarkDown files, you are not constrained to either of the above options but can simply clone this git repository locally and work with your text editor of choice, such as vim, emacs, VSCode, Sublime, or something specifically geared for comfortable Markdown editing such as Zettlr . Version Control As a version control system, git will ensure all versions of the content are tracked throughout their history. You can use git tools to revert to previous versions if needed. It also offers an exact provenance trail of who edited what and when, offering maximum transparency. Contributions and Maintainers Anybody can contribute directly to the content by simply doing pull requests. The maintainers of this repository review and accept or decline those pull requests. This procedure enables the maintainers to easily collaborate with tool and data developers. The maintainers, from CLARIAH's communication department, are: Sebastiaan Fluitsma Emma Verbree Liselore Tissen","title":"Ineo Content"},{"location":"#ineo-content","text":"At this stage this repository is a proposal!","title":"Ineo Content"},{"location":"#introduction","text":"This repository stores the rich content for the Ineo Resource finder. We denote the various curated texts pertaining to resources as 'rich content'. A select team of CLARIAH's communication department is working on these texts. This repository enables easy collaboration, also with developers and data providers, and provides a sustainable storage solution. Rich content can be contrasted to the automatically harvested metadata that results from the CLARIAH Tool Discovery track or the FAIR Datasets track and is not supposed to overlap. For automatically harvested metadata, the primary authorship lies with the tool/data producer. For rich user content, it lies with the people of the communication department (WP1). The rich content in this repository is stored in Markdown format , a simple plain text format for text markup. We follow a specific structure to the data can be easily ingested into Ineo, as well as any other systems who want to make use of it. The content can be previewed directly on https://clariah.github.io/ineo-content . We used a simple static site generator ( MkDocs ) to achieve this. That site, however, is not intended for end-users to be used directly. On the preview site we also provide access to a simple headless CMS to facilitate working with the Markdown files in the git repository, without requiring real technical knowledge of either.","title":"Introduction"},{"location":"#directory-structure","text":"Directories: src/ - Contains Markdown texts tools/ - Contains Markdown texts describing tools. data/ - Contains Markdown texts describing data workflows/ - Contains Markdown texts describing workflows standards/ - Contains Markdown texts describing standards media/ - Stores images or other associated media files, Right now all media files are in this single folder, without subfolders, this limitation is only due to the admin CMS. Images or downloadable documents/spreadsheets/presentations that are referenced from one of the markdown files may be included in this subdirectory as well. You can reference images from the markdown files, just use /media/ as URL prefix when doing so. You can also reference media elsewhere on the web, always sure to use https:// in that case. This should probably be kept to a minimum as there is no guarantee such media will persist in that location over time. Videos are not suitable for direct inclusion in the git repository as they are too big, they need to be hosted elsewhere. Ensure the media files you upload here are suitable for use on the web, pay attention to file-size, format and resolution. Within these directories, each resource is described by a single Markdown file, with optional YAML frontmatter . The title of the markdown file (a level-one heading, e.g. # ) corresponds with the title of the resource as shown in the frontend. The extension is always .md . The paragraph(s) immediately succeeding the level-one heading are taken to be the description, for tools (unless it concerns a tool suite), this generally be omitted as the description should be automatically drawn from the metadata. It is recommended to keep filename to a simple subset of lowercase ASCII characters, without spaces or any punctuation aside from dashes. The markdown file contains sections marked with level two headings ( ## ), each should correspond to agreed-upon tabs shown in the Ineo frontend, we currently distinguish the following: Overview Learn Mentions The content editors and frontend developers can introduce new ones when needed. Any subsections (level-three headings and beyond) can be used freely.","title":"Directory Structure"},{"location":"#yaml-frontmatter","text":"The markdown files can be enriched with YAML frontmatter to convey some extra information. This is NOT intended for extensive tool/data metadata, as those come directly from different data provisioning pipelines and are not kept in this repository. The only metadata we always duplicate is the title of the resource, which typically also determines the filename (in a 'slug' form in lowercase only and with spaces replaced by hyphens). --- title: The title of the resource --- For tools , we use either the identifier or group field to link to https://tools.clariah.nl . The identifier links to an exact resource, such as frog for https://tools.clariah.nl/frog , i.e. it is identical to what appears in the URL. The other one, group , links to a group or tool suite because the level of granularity offered on https://tools.clariah.nl may be too fine-grained compared to what is desirable for Ineo or other portals. It should be exact name of the group as it appears on the tool discovery overview. The name s of the groups an be easily spotted by looking at the table of contents there; the groups are the ones with sub-items. --- identifier: tool title: Tool --- If both identifier and group are set, the identifier is used to associate metadata of one specific tool in the group/suite with the group as a whole. This allows you to still describe a whole tool suite in Ineo, but picks one of the tools in the suite as being its representative and have its metadata prominently features. The following Ineo-specific metadata can be added: (TODO: add specification of part of Ineo's YAML syntax that are reusable. This is something for the Ineo developers to specify.) Ineo currently allows for a carousel widget showing several images in sequence (see for example https://www.ineo.tools/resources/media-suite ). The data definition for such a widget would go in the YAML frontmatter, I would propose something like: --- carousel: - /media/mediasuite-cover1.png - https://vimeo.com/503507411?embedded=true&source=vimeo_logo&owner=115309374 - /media/mediasuite-cover2.png - /media/mediasuite-cover3.png - /media/mediasuite-cover4.png --- Note these are specifically for Ineo and won't be previewed in the editor. Whether you images interspersed in the flowing text (easier) or the carousel is up to the maintainer team to decide. Note that for data, no way of linking to underlying data registry via identifiers has been defined yet (take this up with Menzo).","title":"YAML frontmatter"},{"location":"#template","text":"The following template serves as an example for tools: --- identifier: tool-identifier-from-tools-clariah-nl title: Name of the Tool carousel: - /media/tool-screenshot.png --- # Name of the Tool (a short description can go here) ## Overview (all text you want on the overview tab goes here) ## Learn (all text you want on the learn tab goes here) ## Mentions (all text you want on the mentions tab goes here)","title":"Template"},{"location":"#editing","text":"","title":"Editing"},{"location":"#content-management-system-cms","text":"A headless CMS ( DecapCMS previously known as NetlifyCMS) is available to make it easier for content editors to do their editing. Within the CMS, both the Markdown content and the YAML frontmatter can be edited in a WYSIWYG fashion without knowledge of either Markdown or YAML. A GitHub account is required to edit. The CMS can be accessed here The CMS is a nice convenience but it also enforced some limitations, it has put the following constraints on this specification: All media files are stored in a single directory /media/ and does not allow further divisions in subdirectories.","title":"Content Management System (CMS)"},{"location":"#online-ide","text":"An alternative to using the CMS is to use GitHub's online Visual Studio Code IDE. Each page on https://clariah.github.io/ineo-content has an edit this page link that automatically takes you to the web-based IDE. This offers a bit more freedom than the CMS.","title":"Online IDE"},{"location":"#local-editing","text":"Being a simple git repository with MarkDown files, you are not constrained to either of the above options but can simply clone this git repository locally and work with your text editor of choice, such as vim, emacs, VSCode, Sublime, or something specifically geared for comfortable Markdown editing such as Zettlr .","title":"Local editing"},{"location":"#version-control","text":"As a version control system, git will ensure all versions of the content are tracked throughout their history. You can use git tools to revert to previous versions if needed. It also offers an exact provenance trail of who edited what and when, offering maximum transparency.","title":"Version Control"},{"location":"#contributions-and-maintainers","text":"Anybody can contribute directly to the content by simply doing pull requests. The maintainers of this repository review and accept or decline those pull requests. This procedure enables the maintainers to easily collaborate with tool and data developers. The maintainers, from CLARIAH's communication department, are: Sebastiaan Fluitsma Emma Verbree Liselore Tissen","title":"Contributions and Maintainers"},{"location":"tools/frog/","text":"Frog Frog is an integration of memory-based natural language processing (NLP) modules developed for Dutch. It performs automatic linguistic enrichment such as part of speech tagging, lemmatisation, named entity recognition, shallow parsing, dependency parsing and morphological analysis. Overview Frog is an integration of memory-based natural language processing (NLP) modules developed for Dutch. Frog performs tokenization, part-of-speech tagging, lemmatization and morphological segmentation of word tokens. At the sentence level Frog identifies non-embedded phrase chunks in the sentence, recognizes named entities and assigns a dependency parse graph. Frog produces output in either FoLiA XML or a simple tab-delimited column format with one token per line. Where possible, Frog makes use of multi-processor support to run subtasks in parallel. Frog offers a command-line interface (that can also run as a daemon) and a C++ library. Learn Instruction webpages Mentions Articles (incl. conference papers, presentations and demo\u2019s) Projects Teaching and Instruction","title":"Frog"},{"location":"tools/frog/#frog","text":"Frog is an integration of memory-based natural language processing (NLP) modules developed for Dutch. It performs automatic linguistic enrichment such as part of speech tagging, lemmatisation, named entity recognition, shallow parsing, dependency parsing and morphological analysis.","title":"Frog"},{"location":"tools/frog/#overview","text":"Frog is an integration of memory-based natural language processing (NLP) modules developed for Dutch. Frog performs tokenization, part-of-speech tagging, lemmatization and morphological segmentation of word tokens. At the sentence level Frog identifies non-embedded phrase chunks in the sentence, recognizes named entities and assigns a dependency parse graph. Frog produces output in either FoLiA XML or a simple tab-delimited column format with one token per line. Where possible, Frog makes use of multi-processor support to run subtasks in parallel. Frog offers a command-line interface (that can also run as a daemon) and a C++ library.","title":"Overview"},{"location":"tools/frog/#learn","text":"","title":"Learn"},{"location":"tools/frog/#instruction-webpages","text":"","title":"Instruction webpages"},{"location":"tools/frog/#mentions","text":"","title":"Mentions"},{"location":"tools/frog/#articles-incl-conference-papers-presentations-and-demos","text":"","title":"Articles (incl. conference papers, presentations and demo\u2019s)"},{"location":"tools/frog/#projects","text":"","title":"Projects"},{"location":"tools/frog/#teaching-and-instruction","text":"","title":"Teaching and Instruction"},{"location":"tools/grlc/","text":"grlc grlc makes all your Linked Data accessible to the Web by automatically converting your SPARQL queries into RESTful APIs. Overview grlc is a lightweight server that takes SPARQL queries (stored in a GitHub repository, in your local filesystem, or listed in a URL), and translates them to Linked Data Web APIs. This enables universal access to Linked Data. Users are not required to know SPARQL to query their data, but instead can access a web API. grlc assumes that you have a collection of SPARQL queries as .rq files. grlc will create one API operation for each SPARQL query/.rq file in the collection. Your queries can add API parameters to each operation by using the parameter mapping syntax. This allows your query to define query variables which will be mapped to API parameters for your API operation (see here for an example). Your queries can include special decorators to add extra functionality to your API. Learn Instruction webpages The Quick Tutorial is a quick walkthrough for deploying your own Linked Data API using grlc. Mentions Articles (incl. conference papers, presentations and demo\u2019s) Albert Mero\u00f1o-Pe\u00f1uela, Rinke Hoekstra. \u201cgrlc Makes GitHub Taste Like Linked Data APIs\u201d. The Semantic Web \u2013 ESWC 2016 Satellite Events, Heraklion, Crete, Greece, May 29 \u2013 June 2, 2016, Revised Selected Papers. LNCS 9989, pp. 342-353 (2016). (PDF) Albert Mero\u00f1o-Pe\u00f1uela, Rinke Hoekstra. \u201cSPARQL2Git: Transparent SPARQL and Linked Data API Curation via Git\u201d. In: Proceedings of the 14th Extended Semantic Web Conference (ESWC 2017), Poster and Demo Track. Portoroz, Slovenia, May 28th \u2013 June 1st, 2017 (2017). (PDF) Albert Mero\u00f1o-Pe\u00f1uela, Rinke Hoekstra. \u201cAutomatic Query-centric API for Routine Access to Linked Data\u201d. In: The Semantic Web \u2013 ISWC 2017, 16th International Semantic Web Conference. Lecture Notes in Computer Science, vol 10587, pp. 334-339 (2017). (PDF) Pasquale Lisena, Albert Mero\u00f1o-Pe\u00f1uela, Tobias Kuhn, Rapha\u00ebl Troncy. \u201cEasy Web API Development with SPARQL Transformer\u201d. In: The Semantic Web \u2013 ISWC 2019, 18th International Semantic Web Conference. Lecture Notes in Computer Science, vol 11779, pp. 454-470 (2019). (PDF) Projects Teaching and Instruction","title":"grlc"},{"location":"tools/grlc/#grlc","text":"grlc makes all your Linked Data accessible to the Web by automatically converting your SPARQL queries into RESTful APIs.","title":"grlc"},{"location":"tools/grlc/#overview","text":"grlc is a lightweight server that takes SPARQL queries (stored in a GitHub repository, in your local filesystem, or listed in a URL), and translates them to Linked Data Web APIs. This enables universal access to Linked Data. Users are not required to know SPARQL to query their data, but instead can access a web API. grlc assumes that you have a collection of SPARQL queries as .rq files. grlc will create one API operation for each SPARQL query/.rq file in the collection. Your queries can add API parameters to each operation by using the parameter mapping syntax. This allows your query to define query variables which will be mapped to API parameters for your API operation (see here for an example). Your queries can include special decorators to add extra functionality to your API.","title":"Overview"},{"location":"tools/grlc/#learn","text":"","title":"Learn"},{"location":"tools/grlc/#instruction-webpages","text":"The Quick Tutorial is a quick walkthrough for deploying your own Linked Data API using grlc.","title":"Instruction webpages"},{"location":"tools/grlc/#mentions","text":"","title":"Mentions"},{"location":"tools/grlc/#articles-incl-conference-papers-presentations-and-demos","text":"Albert Mero\u00f1o-Pe\u00f1uela, Rinke Hoekstra. \u201cgrlc Makes GitHub Taste Like Linked Data APIs\u201d. The Semantic Web \u2013 ESWC 2016 Satellite Events, Heraklion, Crete, Greece, May 29 \u2013 June 2, 2016, Revised Selected Papers. LNCS 9989, pp. 342-353 (2016). (PDF) Albert Mero\u00f1o-Pe\u00f1uela, Rinke Hoekstra. \u201cSPARQL2Git: Transparent SPARQL and Linked Data API Curation via Git\u201d. In: Proceedings of the 14th Extended Semantic Web Conference (ESWC 2017), Poster and Demo Track. Portoroz, Slovenia, May 28th \u2013 June 1st, 2017 (2017). (PDF) Albert Mero\u00f1o-Pe\u00f1uela, Rinke Hoekstra. \u201cAutomatic Query-centric API for Routine Access to Linked Data\u201d. In: The Semantic Web \u2013 ISWC 2017, 16th International Semantic Web Conference. Lecture Notes in Computer Science, vol 10587, pp. 334-339 (2017). (PDF) Pasquale Lisena, Albert Mero\u00f1o-Pe\u00f1uela, Tobias Kuhn, Rapha\u00ebl Troncy. \u201cEasy Web API Development with SPARQL Transformer\u201d. In: The Semantic Web \u2013 ISWC 2019, 18th International Semantic Web Conference. Lecture Notes in Computer Science, vol 11779, pp. 454-470 (2019). (PDF)","title":"Articles (incl. conference papers, presentations and demo\u2019s)"},{"location":"tools/grlc/#projects","text":"","title":"Projects"},{"location":"tools/grlc/#teaching-and-instruction","text":"","title":"Teaching and Instruction"},{"location":"tools/mediasuite/","text":"Media Suite The CLARIAH Media Suite is a research environment of the Dutch infrastructure for digital humanities and social science. It facilitates scholarly research with large Dutch media collections by providing advanced search and analysis tools. Overview The CLARIAH Media Suite is an application for doing research with data collections by scholars and students at universities and in higher education (e.g., film, television, and other media scholars, oral historians, and political historians). It consists of three building blocks: data, tools to work with the data, and a workspace to store your work with the data. The Media Suite is an innovative digital research environment, an experimental environment (LAB) , in which we are experimenting with new ways of working with multimedia data collections. It caters to various levels of expertise and research interests: from providing access to many audio-visual collections for exploratory research to close reading; and from more complex modes of data analysis to distant reading strategies. The transparent search and analysis tools that the Media Suite offers, combined with its APIs that can be used with Jupyter notebooks, allow for many new possibilities for research and represents the middle ground between full algorithmic literacy and being a data novice. Users from Dutch universities and research institutes can log into the Media Suite using their university credentials. Read more about access to the Media Suite . Data Via the CLARIAH infrastructure, the Media Suite provides access to data collections in Dutch archives (among others: The Netherlands Institute for Sound and Vision, EYE Film Museum collections, DANS oral history interview collections, collections from the Open Images Project). Typically, data collections are registered in a registry that allows the infastructure to either access collections directly or use some form of data harvesting to enables access. More about our data: What collections/data are available via the Media Suite? > How does the Media Suite make the data available? > Can I play/view all the sources that I find via the Media Suite? > Tools As a research environment, the CLARIAH Media Suite aims to support scholars in all the steps of their research process. At a general level, it provides tools for exploring the data and collections, creating personal selections (or corpora), adding annotations (such as tags, comments, links, and other metadata), and the possibility to export them. The Media Suite also facilitates working with data directly by using its APIs in combination with Jupyter Notebooks. Workspace Workspace The CLARIAH Media Suite offers a \u201cvirtual work space\u201d to its users. It allows researchers to store bookmarks, annotations, saved queries, personal collections, or automatic enrichments. The workspace thus provides researchers with novel ways for making transparent and managing their research process. Read more about the Media Suite > Learn Instruction and support The Media Suite Learn pages offer a wide set instruction and support material: Quick start guide Written, video and hybrid tutorials for different levels of user expertise, beginner\u2019s to advanced levels, based on subject or tool: Subject tutorials , Tool tutorials Frequently Asked Questions Glossary of terms Overview of example projects that have used Media Suite collections and tools in either teaching or research. Media Suite\u2019s Group Library in Zotero. Advice and user support Media Suite Learn team aims to support a wide array of approaches and areas of teaching and research, and are happy to offer advice on how to use the Media Suite productively in your own project. You can contact the team via mediastudies@clariah.nl . The team regularly contributes to organising research events that introduce the Media Suite to new users, and that reflect on digital methods and videographic approaches more broadly. Events include online webinars and public research seminars focussing on state-of-the-art digital scholarship, with contributions from scholars from the Netherlands and abroad. Public forum The Media Suite Public Forum uses Gitter , an open source instant messaging and chat room system. To start chatting, you would need to have either a Twitter or Github account. Media Suite related questions & answers Bug reports Discussions on new features and future directions Mentions Publications Aasman, S., Melgar Estrada, L., Slootweg, T. & Wegter, R., (2019). Tales of a Tool Encounter: Exploring Video Annotation for Doing Media History, VIEW Journal of European Television History and Culture, Special Issue on Audiovisual Data in Digital Humanities, eds. Pelle Snickars, Mark Williams and Andreas Fickers, Spring 2019. Open access, online multi-media article. Ashkpour, A., Merono-Penuela, A., & Mandemakers, K. (2015). The Aggregate Dutch Historical Censuses: Harmonization and RDF. Historical Methods: A Journal of Quantitative and Interdisciplinary History, 48(4), 230-245. (PDF) Bilgin, A., Sang, E.T.K., Smeenk, K., Hollink, L., van Ossenbruggen, J., Harbers, F. and Broersma, M. (2018). Utilizing a Transparency-driven Environment toward Trusted Automatic Genre Classification: A Case Study in Journalism History. Proceedings 14th International Conference on e-Science (e-Science) (pp. 486-496). IEEE. Bloothooft, G., Oosterlaken, R., Reynaert, M., Depuydt, K., Schoonheim, T. (2018). NAMES: Towards gold standards for personal names. DHBenelux conference 2018. Broersma, M., & Harbers, F. Eds. (2019). Dossier CLARIAH Media projects. Tijdschrift voor Mediageschiedenis/Journal for Media History. See all publications Presentations Erp, M. van. A philosophy of change, Institute for Social Work, Utrecht, 12 december 2018 Dijk, J. van. Towards Semantic enrichment of Newspapers: A Historical Ecology use case, Amsterdam, 28 december 2017 See all presentations Webpages \u2018Big Heritage Data\u2019 in Media Suite, Beeld en geluid Media Suite makes \u2018Big Heritage Data\u2019 accessible for research, DANS Video\u2019s Talkshow Mediasuite // Data Stories, Dutch Media Week","title":"Media Suite"},{"location":"tools/mediasuite/#media-suite","text":"The CLARIAH Media Suite is a research environment of the Dutch infrastructure for digital humanities and social science. It facilitates scholarly research with large Dutch media collections by providing advanced search and analysis tools.","title":"Media Suite"},{"location":"tools/mediasuite/#overview","text":"The CLARIAH Media Suite is an application for doing research with data collections by scholars and students at universities and in higher education (e.g., film, television, and other media scholars, oral historians, and political historians). It consists of three building blocks: data, tools to work with the data, and a workspace to store your work with the data. The Media Suite is an innovative digital research environment, an experimental environment (LAB) , in which we are experimenting with new ways of working with multimedia data collections. It caters to various levels of expertise and research interests: from providing access to many audio-visual collections for exploratory research to close reading; and from more complex modes of data analysis to distant reading strategies. The transparent search and analysis tools that the Media Suite offers, combined with its APIs that can be used with Jupyter notebooks, allow for many new possibilities for research and represents the middle ground between full algorithmic literacy and being a data novice. Users from Dutch universities and research institutes can log into the Media Suite using their university credentials. Read more about access to the Media Suite .","title":"Overview"},{"location":"tools/mediasuite/#data","text":"Via the CLARIAH infrastructure, the Media Suite provides access to data collections in Dutch archives (among others: The Netherlands Institute for Sound and Vision, EYE Film Museum collections, DANS oral history interview collections, collections from the Open Images Project). Typically, data collections are registered in a registry that allows the infastructure to either access collections directly or use some form of data harvesting to enables access. More about our data: What collections/data are available via the Media Suite? > How does the Media Suite make the data available? > Can I play/view all the sources that I find via the Media Suite? >","title":"Data"},{"location":"tools/mediasuite/#tools","text":"As a research environment, the CLARIAH Media Suite aims to support scholars in all the steps of their research process. At a general level, it provides tools for exploring the data and collections, creating personal selections (or corpora), adding annotations (such as tags, comments, links, and other metadata), and the possibility to export them. The Media Suite also facilitates working with data directly by using its APIs in combination with Jupyter Notebooks. Workspace","title":"Tools"},{"location":"tools/mediasuite/#workspace","text":"The CLARIAH Media Suite offers a \u201cvirtual work space\u201d to its users. It allows researchers to store bookmarks, annotations, saved queries, personal collections, or automatic enrichments. The workspace thus provides researchers with novel ways for making transparent and managing their research process. Read more about the Media Suite >","title":"Workspace"},{"location":"tools/mediasuite/#learn","text":"","title":"Learn"},{"location":"tools/mediasuite/#instruction-and-support","text":"The Media Suite Learn pages offer a wide set instruction and support material: Quick start guide Written, video and hybrid tutorials for different levels of user expertise, beginner\u2019s to advanced levels, based on subject or tool: Subject tutorials , Tool tutorials Frequently Asked Questions Glossary of terms Overview of example projects that have used Media Suite collections and tools in either teaching or research. Media Suite\u2019s Group Library in Zotero.","title":"Instruction and support"},{"location":"tools/mediasuite/#advice-and-user-support","text":"Media Suite Learn team aims to support a wide array of approaches and areas of teaching and research, and are happy to offer advice on how to use the Media Suite productively in your own project. You can contact the team via mediastudies@clariah.nl . The team regularly contributes to organising research events that introduce the Media Suite to new users, and that reflect on digital methods and videographic approaches more broadly. Events include online webinars and public research seminars focussing on state-of-the-art digital scholarship, with contributions from scholars from the Netherlands and abroad.","title":"Advice and user support"},{"location":"tools/mediasuite/#public-forum","text":"The Media Suite Public Forum uses Gitter , an open source instant messaging and chat room system. To start chatting, you would need to have either a Twitter or Github account. Media Suite related questions & answers Bug reports Discussions on new features and future directions","title":"Public forum"},{"location":"tools/mediasuite/#mentions","text":"","title":"Mentions"},{"location":"tools/mediasuite/#publications","text":"Aasman, S., Melgar Estrada, L., Slootweg, T. & Wegter, R., (2019). Tales of a Tool Encounter: Exploring Video Annotation for Doing Media History, VIEW Journal of European Television History and Culture, Special Issue on Audiovisual Data in Digital Humanities, eds. Pelle Snickars, Mark Williams and Andreas Fickers, Spring 2019. Open access, online multi-media article. Ashkpour, A., Merono-Penuela, A., & Mandemakers, K. (2015). The Aggregate Dutch Historical Censuses: Harmonization and RDF. Historical Methods: A Journal of Quantitative and Interdisciplinary History, 48(4), 230-245. (PDF) Bilgin, A., Sang, E.T.K., Smeenk, K., Hollink, L., van Ossenbruggen, J., Harbers, F. and Broersma, M. (2018). Utilizing a Transparency-driven Environment toward Trusted Automatic Genre Classification: A Case Study in Journalism History. Proceedings 14th International Conference on e-Science (e-Science) (pp. 486-496). IEEE. Bloothooft, G., Oosterlaken, R., Reynaert, M., Depuydt, K., Schoonheim, T. (2018). NAMES: Towards gold standards for personal names. DHBenelux conference 2018. Broersma, M., & Harbers, F. Eds. (2019). Dossier CLARIAH Media projects. Tijdschrift voor Mediageschiedenis/Journal for Media History. See all publications","title":"Publications"},{"location":"tools/mediasuite/#presentations","text":"Erp, M. van. A philosophy of change, Institute for Social Work, Utrecht, 12 december 2018 Dijk, J. van. Towards Semantic enrichment of Newspapers: A Historical Ecology use case, Amsterdam, 28 december 2017 See all presentations","title":"Presentations"},{"location":"tools/mediasuite/#webpages","text":"\u2018Big Heritage Data\u2019 in Media Suite, Beeld en geluid Media Suite makes \u2018Big Heritage Data\u2019 accessible for research, DANS","title":"Webpages"},{"location":"tools/mediasuite/#videos","text":"Talkshow Mediasuite // Data Stories, Dutch Media Week","title":"Video\u2019s"},{"location":"tools/stam/","text":"STAM Stand-off Text Annotation Model (STAM) is a data model for stand-off-text annotation where any information on a text is represented as an annotation. Overview STAM is a minimalist data model for stand-off text annotation. Any information on a text is represented an annotation, which can be any kind of remarks, classifications, or tags on specific portions of the text or the entire resource. Annotations can also point to other annotations (higher-order annotations). STAM does not define specific vocabularies and accepts plain text as its base resource. It is independent of complex data models like RDF, W3C Web Annotations, TEI, or FoLiA. STAM aims to be a functional and practical solution, allowing users to use use vocabularies that are formalised elsewhere. STAM is primarily intended as a model for data representation, and less so as a format for data interchange. It is designed in such as way that an efficient implementation (both speed & memory) is feasible. Goals/characteristics of STAM are: Simplicity - the data model must be easy to understand for a user/developer to use and only contain what is needed, not more. We provide a minimal foundation upon which other projects can build more complex solutions. These are deliberately kept out of STAM itself. The notion that everything is an annotation is at the core of STAM and one of the things that keeps it simple. Separation from semantics - The data model does not commit to any vocabulary or annotation paradigm. It must be flexible enough to express whatever annotation paradigm a researcher wants to use, yet provide the facilities to be specific enough for practical purposes. The model basically allows for any kind of directed or undirected graph. Standalone - No dependency on other data models (e.g. RDF) aside from Unicode and JSON for serialisation, no dependency on any software services. Practical - Rather than provide a theoretical framework, we primarily aim to provide a practical specification and actual low-level tooling you can get to work with right away. Performant - The data model is set up in such a way that it allows for efficient/performant implementations, with regard to processing requirements but especially memory consumption. The model should be suitable for big data (millions of annotations). We sit at a point where we deem to have an optimal trade-off between simplicity and performance. Import & Export - Reads/writes a simple JSON format. But also designed with export to more complex formats in mind (such as W3C Web Annotations / RDF) and imports from common formats such as TSV and CONLL. Note that although STAM puts no constraints on annotation paradigms and vocabularies, higher data models may. The name STAM, an acronym for \" Stand-off Text Annotation Model \", is Dutch, Swedish, Afrikaans and Frisian for \" trunk \" (as in the trunk of a tree), the name itself depicts a solid foundation upon which more elaborate solutions can be built. If you want to learn more, please have a look at the specification on project's github page and at the implementations mentioned below: Implementations There are currently two implementations for STAM: stam-rust - A STAM library written in Rust, aims to be a full STAM implementation with high performance and memory-based storage model. stam-python - A STAM library for Python. This is not an independent implementation but it is a Python binding to the above Rust library. Furthermore, there is also the following implementation that builds upon the primary STAM library: stam-tools - A set of command-line tools to work with STAM Learn STAM Specification The STAM specification lays out the data model of STAM in formal terms, and is a complete source to understand what STAM is all about: STAM Specification Python Tutorial: Standoff Text Annotation for Pythonistas To get hands-on experience with STAM from Python, please consult this tutorial, which comes in the form of a Jupyter Notebook you can run interactively: STAM Tutorial: Standoff Text Annotation for Pythonistas The full Python API is documented here: API Reference Rust library The core library for STAM is implemented in Rust. It is also used by the Python binding. Advanced programmers may also use it directly to build efficient applications that deal with stand-off annotation on text: stam-rust: STAM library for Rust API Reference Extensions STAM is kept simple and only the bare minimum is defined. Other functionality is included in extensions. Extensions do one or more of the following: they extend the data model, specify new serialisations, specify mappings/crosswalks to other paradigms/formats, specify additional functionality. The following are currently defined: STAM-Vocab - Allows expressing and validating against user-defined vocabularies. STAM-Webannotations - Models W3C Web Annotations using STAM and vice versa. STAM-Textvalidation - Adds an extra redundancy layer that helps protecting data integrity and aids readability of serialisations STAM-CSV - Defines an alternative serialisation format using CSV. STAM-Baseoffset - allows splitting large monolithic text resources into multiple smaller text resources, whilst still retaining the ability the reference offsets as if they refer to the original/monolithic resource. Implementations SHOULD explicitly state which extensions they support. For more information, have a look at the README .","title":"STAM"},{"location":"tools/stam/#stam","text":"Stand-off Text Annotation Model (STAM) is a data model for stand-off-text annotation where any information on a text is represented as an annotation.","title":"STAM"},{"location":"tools/stam/#overview","text":"STAM is a minimalist data model for stand-off text annotation. Any information on a text is represented an annotation, which can be any kind of remarks, classifications, or tags on specific portions of the text or the entire resource. Annotations can also point to other annotations (higher-order annotations). STAM does not define specific vocabularies and accepts plain text as its base resource. It is independent of complex data models like RDF, W3C Web Annotations, TEI, or FoLiA. STAM aims to be a functional and practical solution, allowing users to use use vocabularies that are formalised elsewhere. STAM is primarily intended as a model for data representation, and less so as a format for data interchange. It is designed in such as way that an efficient implementation (both speed & memory) is feasible.","title":"Overview"},{"location":"tools/stam/#goalscharacteristics-of-stam-are","text":"Simplicity - the data model must be easy to understand for a user/developer to use and only contain what is needed, not more. We provide a minimal foundation upon which other projects can build more complex solutions. These are deliberately kept out of STAM itself. The notion that everything is an annotation is at the core of STAM and one of the things that keeps it simple. Separation from semantics - The data model does not commit to any vocabulary or annotation paradigm. It must be flexible enough to express whatever annotation paradigm a researcher wants to use, yet provide the facilities to be specific enough for practical purposes. The model basically allows for any kind of directed or undirected graph. Standalone - No dependency on other data models (e.g. RDF) aside from Unicode and JSON for serialisation, no dependency on any software services. Practical - Rather than provide a theoretical framework, we primarily aim to provide a practical specification and actual low-level tooling you can get to work with right away. Performant - The data model is set up in such a way that it allows for efficient/performant implementations, with regard to processing requirements but especially memory consumption. The model should be suitable for big data (millions of annotations). We sit at a point where we deem to have an optimal trade-off between simplicity and performance. Import & Export - Reads/writes a simple JSON format. But also designed with export to more complex formats in mind (such as W3C Web Annotations / RDF) and imports from common formats such as TSV and CONLL. Note that although STAM puts no constraints on annotation paradigms and vocabularies, higher data models may. The name STAM, an acronym for \" Stand-off Text Annotation Model \", is Dutch, Swedish, Afrikaans and Frisian for \" trunk \" (as in the trunk of a tree), the name itself depicts a solid foundation upon which more elaborate solutions can be built. If you want to learn more, please have a look at the specification on project's github page and at the implementations mentioned below:","title":"Goals/characteristics of STAM are:"},{"location":"tools/stam/#implementations","text":"There are currently two implementations for STAM: stam-rust - A STAM library written in Rust, aims to be a full STAM implementation with high performance and memory-based storage model. stam-python - A STAM library for Python. This is not an independent implementation but it is a Python binding to the above Rust library. Furthermore, there is also the following implementation that builds upon the primary STAM library: stam-tools - A set of command-line tools to work with STAM","title":"Implementations"},{"location":"tools/stam/#learn","text":"","title":"Learn"},{"location":"tools/stam/#stam-specification","text":"The STAM specification lays out the data model of STAM in formal terms, and is a complete source to understand what STAM is all about: STAM Specification","title":"STAM Specification"},{"location":"tools/stam/#python-tutorial-standoff-text-annotation-for-pythonistas","text":"To get hands-on experience with STAM from Python, please consult this tutorial, which comes in the form of a Jupyter Notebook you can run interactively: STAM Tutorial: Standoff Text Annotation for Pythonistas The full Python API is documented here: API Reference","title":"Python Tutorial: Standoff Text Annotation for Pythonistas"},{"location":"tools/stam/#rust-library","text":"The core library for STAM is implemented in Rust. It is also used by the Python binding. Advanced programmers may also use it directly to build efficient applications that deal with stand-off annotation on text: stam-rust: STAM library for Rust API Reference","title":"Rust library"},{"location":"tools/stam/#extensions","text":"STAM is kept simple and only the bare minimum is defined. Other functionality is included in extensions. Extensions do one or more of the following: they extend the data model, specify new serialisations, specify mappings/crosswalks to other paradigms/formats, specify additional functionality. The following are currently defined: STAM-Vocab - Allows expressing and validating against user-defined vocabularies. STAM-Webannotations - Models W3C Web Annotations using STAM and vice versa. STAM-Textvalidation - Adds an extra redundancy layer that helps protecting data integrity and aids readability of serialisations STAM-CSV - Defines an alternative serialisation format using CSV. STAM-Baseoffset - allows splitting large monolithic text resources into multiple smaller text resources, whilst still retaining the ability the reference offsets as if they refer to the original/monolithic resource. Implementations SHOULD explicitly state which extensions they support. For more information, have a look at the README .","title":"Extensions"}]}